{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 4661: Introduction to Data Science\n",
    "## Jay Tandel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: KNN Classification in sklearn\n",
    "Write and submit your python codes in “Jupyter Notebook” to perform the following tasks (submit the .ipynb file).  Make sure to provide proper descriptions as MarkDown for each section of your code (each section of the code must have a short meaningful description right before that, describing what this part of the code is supposed to do!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n",
    "Read the iris flower dataset from the following URL: https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv (Links to an external site.) and assign it to a Pandas DataFrame as you learned in tutorial Lab2-3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width    species\n",
      "0             5.1          3.5           1.4          0.2     setosa\n",
      "1             4.9          3.0           1.4          0.2     setosa\n",
      "2             4.7          3.2           1.3          0.2     setosa\n",
      "3             4.6          3.1           1.5          0.2     setosa\n",
      "4             5.0          3.6           1.4          0.2     setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  virginica\n",
      "146           6.3          2.5           5.0          1.9  virginica\n",
      "147           6.5          3.0           5.2          2.0  virginica\n",
      "148           6.2          3.4           5.4          2.3  virginica\n",
      "149           5.9          3.0           5.1          1.8  virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reading the csv file from web, and store it in panda DataFrame\n",
    "iris_df = pd.read_csv('https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv')\n",
    "\n",
    "#print the imported dataset\n",
    "print(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Feature Matrix for iris dataset:\n",
    "\n",
    "# create a python list of feature names that would like to pick from the dataset:\n",
    "feature_cols = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "\n",
    "# use the above list to select the features from the original DataFrame\n",
    "X = iris_df[feature_cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a Series of labels (the last column) from the DataFrame\n",
    "y = iris_df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n",
    "Split the dataset into testing and training sets with the following parameters: test_size=0.4, random_state=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splitting the original dataset into training set and testing set\n",
    "# The function\"train_test_split\" from \"sklearn.cross_validation\" library performs random splitting.\n",
    "# \"test_size=0.4\" means that pick 40% of data samples for testing set, and the rest (60%) for training set.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width\n",
      "83            6.0          2.7           5.1          1.6\n",
      "60            5.0          2.0           3.5          1.0\n",
      "99            5.7          2.8           4.1          1.3\n",
      "100           6.3          3.3           6.0          2.5\n",
      "94            5.6          2.7           4.2          1.3\n",
      "..            ...          ...           ...          ...\n",
      "148           6.2          3.4           5.4          2.3\n",
      "79            5.7          2.6           3.5          1.0\n",
      "109           7.2          3.6           6.1          2.5\n",
      "106           4.9          2.5           4.5          1.7\n",
      "138           6.0          3.0           4.8          1.8\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "\n",
      "\n",
      "83     versicolor\n",
      "60     versicolor\n",
      "99     versicolor\n",
      "100     virginica\n",
      "94     versicolor\n",
      "          ...    \n",
      "148     virginica\n",
      "79     versicolor\n",
      "109     virginica\n",
      "106     virginica\n",
      "138     virginica\n",
      "Name: species, Length: 90, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print the training set:\n",
    "print(X_train)\n",
    "print('\\n')\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width\n",
      "4             5.0          3.6           1.4          0.2\n",
      "116           6.5          3.0           5.5          1.8\n",
      "2             4.7          3.2           1.3          0.2\n",
      "23            5.1          3.3           1.7          0.5\n",
      "123           6.3          2.7           4.9          1.8\n",
      "96            5.7          2.9           4.2          1.3\n",
      "134           6.1          2.6           5.6          1.4\n",
      "39            5.1          3.4           1.5          0.2\n",
      "137           6.4          3.1           5.5          1.8\n",
      "53            5.5          2.3           4.0          1.3\n",
      "127           6.1          3.0           4.9          1.8\n",
      "81            5.5          2.4           3.7          1.0\n",
      "115           6.4          3.2           5.3          2.3\n",
      "135           7.7          3.0           6.1          2.3\n",
      "74            6.4          2.9           4.3          1.3\n",
      "119           6.0          2.2           5.0          1.5\n",
      "105           7.6          3.0           6.6          2.1\n",
      "51            6.4          3.2           4.5          1.5\n",
      "92            5.8          2.6           4.0          1.2\n",
      "32            5.2          4.1           1.5          0.1\n",
      "37            4.9          3.1           1.5          0.1\n",
      "120           6.9          3.2           5.7          2.3\n",
      "44            5.1          3.8           1.9          0.4\n",
      "0             5.1          3.5           1.4          0.2\n",
      "55            5.7          2.8           4.5          1.3\n",
      "72            6.3          2.5           4.9          1.5\n",
      "87            6.3          2.3           4.4          1.3\n",
      "102           7.1          3.0           5.9          2.1\n",
      "30            4.8          3.1           1.6          0.2\n",
      "93            5.0          2.3           3.3          1.0\n",
      "45            4.8          3.0           1.4          0.3\n",
      "59            5.2          2.7           3.9          1.4\n",
      "16            5.4          3.9           1.3          0.4\n",
      "13            4.3          3.0           1.1          0.1\n",
      "133           6.3          2.8           5.1          1.5\n",
      "128           6.4          2.8           5.6          2.1\n",
      "64            5.6          2.9           3.6          1.3\n",
      "146           6.3          2.5           5.0          1.9\n",
      "95            5.7          3.0           4.2          1.2\n",
      "49            5.0          3.3           1.4          0.2\n",
      "17            5.1          3.5           1.4          0.3\n",
      "103           6.3          2.9           5.6          1.8\n",
      "71            6.1          2.8           4.0          1.3\n",
      "61            5.9          3.0           4.2          1.5\n",
      "46            5.1          3.8           1.6          0.2\n",
      "12            4.8          3.0           1.4          0.1\n",
      "52            6.9          3.1           4.9          1.5\n",
      "27            5.2          3.5           1.5          0.2\n",
      "34            4.9          3.1           1.5          0.1\n",
      "54            6.5          2.8           4.6          1.5\n",
      "118           7.7          2.6           6.9          2.3\n",
      "117           7.7          3.8           6.7          2.2\n",
      "121           5.6          2.8           4.9          2.0\n",
      "6             4.6          3.4           1.4          0.3\n",
      "111           6.4          2.7           5.3          1.9\n",
      "18            5.7          3.8           1.7          0.3\n",
      "38            4.4          3.0           1.3          0.2\n",
      "20            5.4          3.4           1.7          0.2\n",
      "58            6.6          2.9           4.6          1.3\n",
      "108           6.7          2.5           5.8          1.8\n",
      "\n",
      "\n",
      "4          setosa\n",
      "116     virginica\n",
      "2          setosa\n",
      "23         setosa\n",
      "123     virginica\n",
      "96     versicolor\n",
      "134     virginica\n",
      "39         setosa\n",
      "137     virginica\n",
      "53     versicolor\n",
      "127     virginica\n",
      "81     versicolor\n",
      "115     virginica\n",
      "135     virginica\n",
      "74     versicolor\n",
      "119     virginica\n",
      "105     virginica\n",
      "51     versicolor\n",
      "92     versicolor\n",
      "32         setosa\n",
      "37         setosa\n",
      "120     virginica\n",
      "44         setosa\n",
      "0          setosa\n",
      "55     versicolor\n",
      "72     versicolor\n",
      "87     versicolor\n",
      "102     virginica\n",
      "30         setosa\n",
      "93     versicolor\n",
      "45         setosa\n",
      "59     versicolor\n",
      "16         setosa\n",
      "13         setosa\n",
      "133     virginica\n",
      "128     virginica\n",
      "64     versicolor\n",
      "146     virginica\n",
      "95     versicolor\n",
      "49         setosa\n",
      "17         setosa\n",
      "103     virginica\n",
      "71     versicolor\n",
      "61     versicolor\n",
      "46         setosa\n",
      "12         setosa\n",
      "52     versicolor\n",
      "27         setosa\n",
      "34         setosa\n",
      "54     versicolor\n",
      "118     virginica\n",
      "117     virginica\n",
      "121     virginica\n",
      "6          setosa\n",
      "111     virginica\n",
      "18         setosa\n",
      "38         setosa\n",
      "20         setosa\n",
      "58     versicolor\n",
      "108     virginica\n",
      "Name: species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print the testing set:\n",
    "print(X_test)\n",
    "print('\\n')\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n",
    "Instantiate a KNN object with K=3, train it on the training set and test it on the testing set. Then, calculate the accuracy of your prediction as you learned in Lab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating object of KNeighborsClassifier \"class\" with k=3:\n",
    "\n",
    "k = 3\n",
    "my_knn = KNeighborsClassifier(n_neighbors=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model with train dataset we created using split\n",
    "\n",
    "# We use the method \"fit\" of the object along with training dataset and labels to train the model.\n",
    "my_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'virginica' 'setosa' 'setosa' 'virginica' 'versicolor'\n",
      " 'virginica' 'setosa' 'virginica' 'versicolor' 'virginica' 'versicolor'\n",
      " 'virginica' 'virginica' 'versicolor' 'versicolor' 'virginica'\n",
      " 'versicolor' 'versicolor' 'setosa' 'setosa' 'virginica' 'setosa' 'setosa'\n",
      " 'versicolor' 'versicolor' 'versicolor' 'virginica' 'setosa' 'versicolor'\n",
      " 'setosa' 'versicolor' 'setosa' 'setosa' 'versicolor' 'virginica'\n",
      " 'versicolor' 'virginica' 'versicolor' 'setosa' 'setosa' 'virginica'\n",
      " 'versicolor' 'versicolor' 'setosa' 'setosa' 'versicolor' 'setosa'\n",
      " 'setosa' 'versicolor' 'virginica' 'virginica' 'virginica' 'setosa'\n",
      " 'virginica' 'setosa' 'setosa' 'setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Testing the model with test dataset we created using split\n",
    "\n",
    "# store the predicted values in y_predit\n",
    "y_predict = my_knn.predict(X_test)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using KNN classifier with k = 3 is:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy of the prediction \n",
    "\n",
    "# we use accuracy_score function\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print('Accuracy using KNN classifier with k = 3 is: ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D\n",
    "Repeat part (c) for K=1, K=5, K=7, K=11, K=15, K=27, K=59 (you can simply use a “for loop,” and save the final accuracy results in a list). Does the accuracy always get better by increasing the value K?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial k_list different values of k\n",
    "# Create an empty accuracy_list to store the accuracy score with different k's\n",
    "k_list = [1, 5, 7, 11, 15, 27, 59]\n",
    "accuracy_list = [] \n",
    "\n",
    "# run for loop to train the model and calculate the acuuracy score\n",
    "for k in k_list:\n",
    "    my_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    my_knn.fit(X_train, y_train)\n",
    "    y_predict = my_knn.predict(X_test)\n",
    "    accuracy_list.append(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using KNN classifier with \n",
      "k =  1 is:  0.95\n",
      "k =  5 is:  0.9833333333333333\n",
      "k =  7 is:  0.9666666666666667\n",
      "k =  11 is:  0.9666666666666667\n",
      "k =  15 is:  0.9333333333333333\n",
      "k =  27 is:  0.9166666666666666\n",
      "k =  59 is:  0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score with respective value of k\n",
    "print('Accuracy using KNN classifier with ')\n",
    "for i in range(len(k_list)):\n",
    "    print('k = ',k_list[i] ,'is: ',accuracy_list[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy does not always get better by increasing the value of K\n"
     ]
    }
   ],
   "source": [
    "# print answer for given question\n",
    "print('The accuracy does not always get better by increasing the value of K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E\n",
    "Now, suppose that we would like to make prediction based on only ONE single feature. To find the best single feature, we have to try every feature individually. In other word, we have to repeat part (c) with K=3, four times (each time using only one of the 4 features), and compute the accuracy each time. Then, check the accuracies. \n",
    "Which individual feature provide the best accuracy (the best feature)?  Which one is the second best feature? (Note: you have to train, test, and evaluate your model 4 times, each time on a dataset including only one of the features, and save the final accuracy results in a list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inlitialize the list of features\n",
    "# Create an empty list accuracy_score to store the accuracy score for each feature\n",
    "\n",
    "features = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "accuracy_scores = []\n",
    "k=3\n",
    "\n",
    "# run for loop to train the model and calculate the acuuracy score\n",
    "for current_feature in features:\n",
    "    my_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    my_knn.fit(X_train[[current_feature]], y_train)\n",
    "    y_predict = my_knn.predict(X_test[[current_feature]])\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using KNN classifier with \n",
      "k =  sepal_length is:  0.7166666666666667\n",
      "k =  sepal_width is:  0.5666666666666667\n",
      "k =  petal_length is:  0.9333333333333333\n",
      "k =  petal_width is:  0.95\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score with respective feature\n",
    "\n",
    "print('Accuracy using KNN classifier with ')\n",
    "for i in range(len(features)):\n",
    "    print('k = ',features[i] ,'is: ',accuracy_scores[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best feature is petal_width with accuracy score of 0.95\n",
      "The second best feature is petal_length with accuracy score of 0.9333\n"
     ]
    }
   ],
   "source": [
    "# print answer for given question\n",
    "\n",
    "print('The best feature is petal_width with accuracy score of 0.95')\n",
    "print('The second best feature is petal_length with accuracy score of 0.9333')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F\n",
    "Now, we want to repeat part (e), this time using two features. you have to train, test, and evaluate your model for 6 different cases: using (1st and 2nd features), (1st and 3rd features), (1st and 4th  features), (2nd  and 3rd  features), (2nd and 4th features), (3rd and 4th  features)!    \n",
    "Which “feature pair” provides the best accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the feature_pairs using combination function of itertools librabry\n",
    "feature_pairs = list(combinations(features,2))\n",
    "\n",
    "# Create an empty list accuracy_score to store the accuracy score for each feature pairs\n",
    "accuracy_scores = []\n",
    "k=3\n",
    "\n",
    "# run for loop to train the model and calculate the acuuracy score\n",
    "for i in list(feature_pairs):\n",
    "    current_pair = list(i).copy()\n",
    "    my_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    my_knn.fit(X_train[[current_pair[0],current_pair[1]]], y_train)\n",
    "    y_predict = my_knn.predict(X_test[[current_pair[0], current_pair[1]]])\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using KNN classifier with k = 3 and feature pair\n",
      "('sepal_length', 'sepal_width') is 0.8166666666666667\n",
      "('sepal_length', 'petal_length') is 0.9833333333333333\n",
      "('sepal_length', 'petal_width') is 0.95\n",
      "('sepal_width', 'petal_length') is 0.95\n",
      "('sepal_width', 'petal_width') is 0.95\n",
      "('petal_length', 'petal_width') is 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score with respective feature pair\n",
    "print('Accuracy using KNN classifier with k = 3 and feature pair')\n",
    "for i in range(len(feature_pairs)):\n",
    "    print(feature_pairs[i], 'is', accuracy_scores[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-82bd8b14c2b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # print answer for given question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The feature Pair'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'provides Best Accuracy with accuracy score 0.983'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_pairs' is not defined"
     ]
    }
   ],
   "source": [
    "# # print answer for given question\n",
    "\n",
    "print('The feature Pair', feature_pairs[1], 'provides Best Accuracy with accuracy score 0.983')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G\n",
    "Big Question: Does the “best feature pair” from part (f) contain of both “first best feature” and “second best feature” from part (e)? In other word, can we conclude that the “best two features” for classification are the first best feature along with the second best feature together?\n",
    "\n",
    "No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Summary\n",
    "\n",
    "### D\n",
    "#### Does the accuracy always get better by increasing the value K?\n",
    "#### Answer: NO\n",
    "\n",
    "### E\n",
    "#### Which individual feature provide the best accuracy (the best feature)?  Which one is the second best feature?\n",
    "#### Answer: Best Feature - petal_width with accuracy score of 0.95\n",
    "####                Second Best Feature  - petal_length with accuracy score of 0.9333\n",
    "\n",
    "### F\n",
    "#### Which “feature pair” provides the best accuracy?\n",
    "#### Answer: The feature Pair ('sepal_length', 'petal_length') provides Best Accuracy with accuracy score 0.983\n",
    "\n",
    "#### G\n",
    "#### Big Question: Does the “best feature pair” from part (f) contain of both “first best feature” and “second best feature” from part (e)?          In other word, can we conclude that the “best two features” for classification are the first best feature along with the second best          feature together?\n",
    "#### Answer: NO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
